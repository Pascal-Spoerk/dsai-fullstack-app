{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "475ff13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5941b554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Month Incident Number        Date of Incident Day of Week Number of Victims under 18 Number of Victims over 18 Number of Offenders under 18 Number of Offenders over 18             Race/Ethnicity of Offenders          Offense(s)                    Offense Location                            Bias  Zip Code APD Sector  Council District\n",
      "0   Jan     2017-241137  01/01/2017 12:00:00 AM         Sun                          0                         1                            0                           1                      White/Not Hispanic  Aggravated Assault                     Park/Playground  Anti-Black or African American   78704.0      Henry               9.0\n",
      "1   Feb     2017-580344  02/01/2017 12:00:00 AM         Wed                          0                         1                            0                           1  Black or African American/Not Hispanic  Aggravated Assault  Highway/Road/Alley/Street/Sidewalk                      Anti-White   78702.0    Charlie               1.0\n",
      "2   Mar     2017-800291  03/21/2017 12:00:00 AM         Tue                          0                         0                            0                           0                                 Unknown         Destruction  Highway/Road/Alley/Street/Sidewalk                     Anti-Jewish   78757.0        Ida               7.0\n",
      "3   Apr    2017-1021534  04/12/2017 12:00:00 AM         Wed                          0                         0                            0                           0                           White/Unknown      Simple Assault              Air/Bus/Train Terminal                     Anti-Jewish   78723.0        Ida               1.0\n",
      "4   May    2017-1351550  05/15/2017 12:00:00 AM         Mon                          1                         0                            1                           2                      White/Not Hispanic      Simple Assault                      Residence/Home                 Anti-Gay (Male)   78750.0       Adam               6.0\n",
      "\n",
      "Model Performance:\n",
      "Accuracy: 0.6481481481481481\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Racism       0.71      0.81      0.76        37\n",
      " Transphobia       0.42      0.29      0.34        17\n",
      "\n",
      "    accuracy                           0.65        54\n",
      "   macro avg       0.57      0.55      0.55        54\n",
      "weighted avg       0.62      0.65      0.63        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('dataset/Hate_Crimes_2017-2025.csv')\n",
    "\n",
    "pd.set_option('display.width', 1000)\n",
    "print(df.head())\n",
    "\n",
    "df = df.drop(columns=[\n",
    "    \"Incident Number\",\n",
    "    \"Date of Incident\",\n",
    "    \"Zip Code\",\n",
    "    \"Council District\"\n",
    "])\n",
    "\n",
    "\n",
    "# Clean column names\n",
    "df.columns = df.columns.str.strip().str.replace(\" \", \"_\").str.replace(\"<\", \"lt\").str.replace(\">\", \"gt\")\n",
    "\n",
    "# Group the bias categories into two broader classes: Racism and Transphobia\n",
    "df['Bias'] = df['Bias'].replace({\n",
    "    'Anti-Black or African American': 'Racism',\n",
    "    'Anti-Black' : \"Racism\",\n",
    "    'Anti-Hispanic' : \"Racism\",\n",
    "    'Anti-Gay': 'Transphobia',\n",
    "    'Anti-Gay (Male)': 'Transphobia',\n",
    "    'Anti-Lesbian/Gay/Bisexual/Transgender (Mixed Group)': 'Transphobia',\n",
    "    'Anti-Transgender': 'Transphobia',\n",
    "    'Anti-Hispanic or Latino': 'Racism',\n",
    "    'Anti-Islamic (Muslim)': 'Racism',\n",
    "    'Anti-Jewish': 'Racism',\n",
    "    'Anti-Arab': 'Racism',\n",
    "    'Anti-Asian': 'Racism',\n",
    "    'Anti-Lesbian/Bisexual/Transgender (Mixed Group)': 'Transphobia',\n",
    "    'Anti-Other Race/Ethnicity/Ancestry': 'Racism',\n",
    "    'Anti-Religion (Other)': 'Racism',\n",
    "    'Anti-White': 'Racism',  \n",
    "})\n",
    "\n",
    "# Define features and label\n",
    "X = df.drop(columns=[\"Bias\"])\n",
    "y = df[\"Bias\"]\n",
    "\n",
    "# Identify categorical and numeric columns\n",
    "categorical_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_cols)\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "# Full model pipeline\n",
    "model = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", RandomForestClassifier(random_state=42, class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "print(\"\\nModel Performance:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, model.predict(X_test)))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, model.predict(X_test)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
